name: RealESRGAN_x4plus_custom  # Назваание вашей модели.
model_type: RealESRGANModel
scale: 1  # значение соотвествует тому в сколько раз будет апскейлить изображение ваша модель. Принимаются только значения 1, 2 и 4.
num_gpu: 1  # количество гпу которые будут использованы при обучении
manual_seed: 0  # это значение подсказки для модели. Можно использовать для отладки, задавая один и тот же параметр seed, результат будет повторяться, то есть можно посмотреть как будет меняться модель в зависимости от датасета. Но можно поставить 0 и не париться. 

high_order_degradation: false  # данный параметр отвечает за использование сложных методов деградации изображения. Значение "false" мне помогло заставить его работать на AMD видеокарте. Однако его лучше не отключать если вы собиараетесь использовать только аугментацию данных при обучении

l1_gt_usm: true
percep_gt_usm: true
gan_gt_usm: true
# Параметры выше могут помочь запустить обучение модели на AMD видеокарте. Если у вас Nvidia, то лучше убрать.
augmentation:
  crop_size: 512  # Выделяемая область кадрирования
  use_flip: true   # Отражение изображения
  flip_prob: 0.5  # Вероятность отражения изображения
  use_rotation: true  # Поворот изображения
  rotation_angle: 30  # Угол вращения (например, 30 градусов)
  use_resize: true  # Изменение размера изорбажения
  resize_scale: 1.0   # Масштабирование (например, 1.0 для сохранения исходного размера)
  use_noise: true  # Использование шума
  noise_prob: 0.5     # Вероятность добавления шума
  noise_std: 0.1      # Стандартное отклонение шума
  use_brightness_contrast: true  # Использование изменения яркости и кронтраста
  brightness_prob: 0.5  # Вероятность изменения яркости
  contrast_prob: 0.5    # Вероятность изменения контраста
  brightness_range: [0.5, 1.5]  # Диапазон изменения яркости
  contrast_range: [0.5, 1.5]    # Диапазон изменения контраста
  use_color_jitter: false  # Использование фильтра изменения цвета
  color_jitter_prob: 0.5  # Вероятность изменения цвета
  color_jitter_strength: 0.3  # Сила изменения цвета
  use_blur: false       # Добавление размытия (если нужно)
  blur_radius: 1.0      # Радиус размытия
  use_sharpen: false    # Добавление резкости (если нужно)
  sharpen_strength: 0.5 # Сила резкости

datasets:
  train:
    name: FH  # Название набора данных
    type: PairedImageDataset  # Тип набора данных, где используются пары изображений (например, GT и LQ). Можно изменить на SingleImageDataset, если у вас только изображения выского разрешения.
    dataroot_gt: dataset/ipsilon4  # Путь к корневой директории с изображениями высокого качества (GT)
    dataroot_lq: dataset/image1  # Путь к корневой директории с изображениями низкого качества (LQ)
    filename_tmpl: '{}'  # Шаблон имени файла (например, '{:04d}.png' для имен вида 0001.png)
    io_backend:
      type: disk  # Использовать дисковое хранилище для ввода/вывода данных, можно изменить на memory для использования озу.
    gt_size: 256  # Размер изображения высокого качества (GT), который будет использоваться, можно изменять только на значения (32, 64, 128, 256, 512 и 1024). Увеличение увеличивает потребление видеопамяти.
    use_hflip: True  # Использовать горизонтальное отражение (флип) для увеличения данных
    use_rot: True  # Использовать вращение для увеличения данных
    use_shuffle: True  # Перемешивать данные в наборе перед каждой эпохой
    num_worker_per_gpu: 4  # Количество рабочих процессов для загрузки данных на каждом GPU. Принимаются только значения кратные 2.
    batch_size_per_gpu: 4 # Количество одновременно обрабатываемых изображений. Увеличение увеличивает потребление видеопамяти. Принимаются только значения кратные 2.
    dataset_enlarge_ratio: 1  # Коэффициент увеличения набора данных (например, 1 означает без увеличения)
    prefetch_mode: cuda  # Использовать CUDA для предварительной загрузки данных (ускоряет процесс загрузки)
    pin_memory: True  # Закрепить память (может ускорить передачу данных между CPU и GPU)



network_g:
  type: SRVGGNetCompact  # Тип сети генератора (SRVGGNetCompact - компактная версия SR-VGGNet)
  num_in_ch: 3  # Количество входных каналов (например, RGB изображение имеет 3 канала)
  num_out_ch: 3  # Количество выходных каналов (например, RGB изображение имеет 3 канала)
  num_feat: 32  # Количество признаков (features) в сети (число фильтров в слоях)
  num_conv: 16  # Количество сверточных слоев (слоев свертки) в сети
# 2 верхних параметра можно увеличивать только вместе. Повышение значения увеличивает потребление видеопамяти, но также увеличивает количество нейроных связей которые строит модель. Положительно влияет на качество, однако большие значения требуют больше вычислительной мощности для апскейла при использовании этой модели. Максимальных значений нет, но если вы рассчитывайте на обработку видео, то желательно использовать нынешние значения, либо в идеале num_feat 64 и num_conv 24 если это что-то весьма комплексное. Минимально лучше не ниже 24 и 12, но это прям для очень простых моделей.
  upscale: 1  # Коэффициент увеличения (например, 1 означает отсутствие увеличения, менять вместе со scale в самом верху.)
  act_type: prelu  # Тип активационной функции (PReLU - Parametric ReLU)

network_d:
  type: UNetDiscriminatorSN  # Тип сети дискриминатора (UNetDiscriminatorSN - дискриминатор с U-Net архитектурой и Spectral Normalization)
  num_in_ch: 3  # Количество входных каналов (например, RGB изображение имеет 3 канала)
  num_feat: 64  # Количество признаков (features) в сети дискриминатора (число фильтров в слоях), лучше не трогать
  skip_connection: True  # Использование пропускных соединений (skip connections) для улучшения качества обучения


path:
  pretrain_network_g:
  param_key_g: params_ema
  strict_load_g: true
  resume_state: ~

train:
  ema_decay: 0.999
  optim_g:
    type: Adam
    lr: !!float 1e-4
    weight_decay: 0
    betas: [0.9, 0.99]
  optim_d:
    type: Adam
    lr: !!float 1e-4
    weight_decay: 0
    betas: [0.9, 0.99]

  scheduler:
    type: MultiStepLR
    milestones: [400000]
    gamma: 0.5

  total_iter: 160000  # Количество иттераций обучения модели. Чем больше - тем лучше точность. Зависит от того, насколько сложная у вас модель. Если у неё на плечах лежит задача например научиться добавлять ореолы ко всем персонажам, то тут может сгодиться и 50к итераций. А если необходимо например эти ореолы убрать, а они предварительно были механически изменены, ещё сверху цвета на картинке неественные и это всё надо исправить, то тут может и 300к не хватит, а около 0.5млн. Может влиять на скорость выполнения итоговой модели только если он по итогу будет очень сложной, в таком случае разница между 50к и 150к во времени обработки апскейла будет ощутимой. 
  warmup_iter: -1

  pixel_opt:
    type: L1Loss
    loss_weight: 1.0
    reduction: mean
  perceptual_opt:
    type: PerceptualLoss
    layer_weights:
      'conv1_2': 0.1
      'conv2_2': 0.1
      'conv3_4': 1
      'conv4_4': 1
      'conv5_4': 1
    vgg_type: vgg19
    use_input_norm: true
    perceptual_weight: !!float 1.0
    style_weight: 0
    range_norm: false
    criterion: l1
  gan_opt:
    type: GANLoss
    gan_type: vanilla
    real_label_val: 1.0
    fake_label_val: 0.0
    loss_weight: !!float 1e-1

  net_d_iters: 1
  net_d_init_iters: 0

logger:
  print_freq: 100  # Частота вывода логов в консоль (например, каждые 100 итераций)
  save_checkpoint_freq: 1000  # Частота сохранения контрольных точек (например, каждые 1000 итераций)
  use_tb_logger: true  # Использовать TensorBoard для логирования (true для включения, false для отключения)
  wandb:
    project: ~  # Имя проекта в WandB (например, 'my_project')
    resume_id: ~  # ID для возобновления прерванной тренировки (если нужно продолжить с определенной контрольной точки)

dist_params:
  backend: nccl
  port: 29500

